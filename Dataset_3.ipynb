{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafedde2-1b88-4ece-a56a-75d89225b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text sequence dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_seq_df = pd.read_csv(\"datasets/train/train_text_seq.csv\")\n",
    "train_seq_X = train_seq_df['input_str'].tolist()\n",
    "train_seq_Y = train_seq_df['label'].tolist()\n",
    "valid_seq_df = pd.read_csv('datasets/valid/valid_text_seq.csv')\n",
    "\n",
    "test_seq_X = pd.read_csv(\"datasets/test/test_text_seq.csv\")['input_str'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e528002d-4da5-45a3-b83c-cd44ff498a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           input_str  label  processed_str  \\\n",
      "0  0000154364642718159661428002624223132284159626...      0  0271828003132   \n",
      "1  0004641596369515436422262614110471596262476161...      0  3695110474761   \n",
      "2  0001543626215965999614422464135806142624051159...      0  5999135804051   \n",
      "3  0000154364224641238614262159689561596284351061...      1  0123889563510   \n",
      "4  0004641899422154362069015966142624761262159661...      1  1899206904761   \n",
      "\n",
      "                              integer_list  \n",
      "0  [0, 2, 7, 1, 8, 2, 8, 0, 0, 3, 1, 3, 2]  \n",
      "1  [3, 6, 9, 5, 1, 1, 0, 4, 7, 4, 7, 6, 1]  \n",
      "2  [5, 9, 9, 9, 1, 3, 5, 8, 0, 4, 0, 5, 1]  \n",
      "3  [0, 1, 2, 3, 8, 8, 9, 5, 6, 3, 5, 1, 0]  \n",
      "4  [1, 8, 9, 9, 2, 0, 6, 9, 0, 4, 7, 6, 1]  \n",
      "00001543646427181596614280026242231322841596262614\n",
      "00046415963695154364222626141104715962624761614284\n",
      "00015436262159659996144224641358061426240511596284\n",
      "00001543642246412386142621596895615962843510614262\n",
      "00046418994221543620690159661426247612621596614284\n",
      "00015966143365815436291942226246428461415962780262\n",
      "00006141596262422464805552371543661433651596284262\n",
      "00005999422159646485262621543661415962621495284614\n",
      "00046415436306991596422570561426261415962622414284\n",
      "00026215962639046442261415436209147902622841596614\n",
      "00061426246415961543642236068209126228461415962713\n",
      "00015436165104222621596464271861428426247611596614\n",
      "00001596262154364644224309700261426261415962845237\n",
      "00047906144222037115436159626246461426215963720284\n",
      "00015436464422187212622154614159626215966142843324\n",
      "00004644222625103159631041543661443096142841596262\n",
      "00061426211918159615436182842246461426229192841596\n",
      "00015436159626242235104641235261461425982841596262\n",
      "00001899614159646436264221543626226261415964790284\n",
      "00015436422159661415611464262310439016141596262284\n",
      "00001495464614422262805515961543636826142621596284\n",
      "00006141596142915436422464262259828461426215962670\n",
      "00046426215436422614523724671159626228461415963070\n",
      "00046426229196144221596139561543615962626469284614\n",
      "00042215436262614326004642327159661428426233881596\n",
      "00004223134159691021543626246461420752846142621596\n",
      "00000422614464159650662621543667026253326142841596\n",
      "00023684422464242515966142621543626215962846145332\n",
      "00002626469614516346415964221543626243102841596614\n",
      "00026242215436464614207513956159614151596614262284\n",
      "00015436430415962368446461426242228427186142621596\n",
      "00001596983142246415436533261426261426228422311596\n",
      "6\n",
      "13\n",
      "The number  appears 332 times in total across all strings.\n",
      "The number  appears in 328 different strings.\n"
     ]
    }
   ],
   "source": [
    "print(train_seq_df.head())\n",
    "# print(train_seq_X[0])\n",
    "train_seq_df['processed_str'] = train_seq_df['input_str']\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('262', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('15436', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('1596', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('000', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('262', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('614', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('284', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('422', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('464', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('000', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0612', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('612', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('4734', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('4764', '', regex=False)\n",
    "train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('6842', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('124382', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('332', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('1918', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('198', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('2', '', regex=False)\n",
    "\n",
    "valid_seq_df['processed_str'] = valid_seq_df['input_str']\n",
    "\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('15436', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('1596', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('000', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('262', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('614', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('284', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('422', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('464', '', regex=False)\n",
    "# valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('000', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('0612', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('612', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('4734', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('4764', '', regex=False)\n",
    "valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('6842', '', regex=False)\n",
    "# valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('124382', '', regex=False)\n",
    "\n",
    "# valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('1', '', regex=False)\n",
    "# valid_seq_df['processed_str'] = valid_seq_df['processed_str'].str.replace('2', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('6144', '0', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('2262', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('2284', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('284', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('159', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0002', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0003', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0004', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0005', '', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0006', '', regex=False)\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('644', '', regex=False)\n",
    "def remove_leading_zeros(seq):\n",
    "    if seq.startswith(\"000\"):\n",
    "        return seq[3:].strip()  # Remove the first three '0's\n",
    "    return seq\n",
    "\n",
    "# Apply the function to remove leading \"000\" from all strings in the dataset\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].apply(remove_leading_zeros)\n",
    "\n",
    "# Step 2: Convert the processed strings into a list of integers\n",
    "# train_seq_df['integer_list'] = train_seq_df['processed_str'].apply(lambda x: list(map(int, x.split())))\n",
    "# train_seq_df['integer_list'] = train_seq_df['processed_str'].apply(lambda x: [int(i)%100000000 for i in x])\n",
    "\n",
    "# Step 3: Pad sequences to ensure uniform input lengths\n",
    "# Adjust max_len based on the desired sequence length\n",
    "# max_len = 50  # Set to your desired length\n",
    "# X_padded = pad_sequences(dataset_df['integer_list'], maxlen=max_len, padding='post')\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0001', '1', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0002', '2', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0003', '3', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0004', '4', regex=False)\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0005', '5', regex=False)\n",
    "# # train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('0006', '6', regex=False)\n",
    "\n",
    "\n",
    "# train_seq_df['processed_str'] = train_seq_df['processed_str'].str.replace('000', '', regex=False)\n",
    "\n",
    "for idx, row in train_seq_df.iterrows():\n",
    "    print(train_seq_df['input_str'][idx])\n",
    "    if idx > 30:  # Print first 10 rows for brevity\n",
    "        break\n",
    "\n",
    "# print(len(train_seq_X[i]))\n",
    "total_count = train_seq_df['processed_str'].str.count(\"999\").sum()\n",
    "# total_count = train_seq_df['input_str'].str.count(\"4262\").sum()\n",
    "\n",
    "# Count how many unique strings contain \"6142\"\n",
    "# emoji = 278,478,578,\n",
    "unique_strings_count = train_seq_df['processed_str'].str.contains(\"999\").sum()\n",
    "# print(len(train_seq_df['processed_str'][0]))\n",
    "print(min(len(x) for x in train_seq_df['processed_str']))\n",
    "print(max(len(x) for x in train_seq_df['processed_str']))\n",
    "# for x in train_seq_df['processed_str'] :\n",
    "#     if len(x) == 33 :\n",
    "#         print(x)\n",
    "\n",
    "\n",
    "# Print results 15436,1596, \n",
    "print(f\"The number  appears {total_count} times in total across all strings.\")\n",
    "print(f\"The number  appears in {unique_strings_count} different strings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "399a9d1e-5dc9-4a93-8441-79a4f74908c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique subsequences: 6775\n",
      "         Subsequence 1 Subsequence 2  Levenshtein Distance\n",
      "4489428           0361          0369                     1\n",
      "22010075          0133          1133                     1\n",
      "9255474           1241          1231                     1\n",
      "15805297          8142           812                     1\n",
      "21213528          9631          9633                     1\n",
      "5575737           3576          3577                     1\n",
      "7862869           8824          8814                     1\n",
      "21213537          9631          9131                     1\n",
      "891906            4493          3493                     1\n",
      "13377455           585           525                     1\n",
      "15247144          2467          2367                     1\n",
      "5029341           0839          0836                     1\n",
      "10547912          5846          5346                     1\n",
      "3019309           4526          4527                     1\n",
      "1625090            103          8103                     1\n",
      "6494148           7847          7047                     1\n",
      "15247122          2467          7467                     1\n",
      "9255320           1241          3241                     1\n",
      "16877126          9469          9409                     1\n",
      "22010083          0133          2133                     1\n",
      "9255512           1241          1281                     1\n",
      "5029418           0839          0139                     1\n",
      "19749708           563          5613                     1\n",
      "1624747            103           101                     1\n",
      "7862559           8824          2824                     1\n",
      "1624756            103          1034                     1\n",
      "18425588          5153           553                     1\n",
      "15805129          8142           142                     1\n",
      "19471375           523           723                     1\n",
      "18425558          5153          6153                     1\n",
      "21213603          9631          5631                     1\n",
      "1624817            103           403                     1\n",
      "1624822            103           803                     1\n",
      "13377367           585          8585                     1\n",
      "12408642          2035          2735                     1\n",
      "3990691           9389          9589                     1\n",
      "5029438           0839          2839                     1\n",
      "16877155          9469          8469                     1\n",
      "9255524           1241          1221                     1\n",
      "7862787           8824          8828                     1\n",
      "15247206          2467          2427                     1\n",
      "5029295           0839          4839                     1\n",
      "19749637           563           163                     1\n",
      "14751416          4790          4792                     1\n",
      "3991165           9389          1389                     1\n",
      "12408089          2035           235                     1\n",
      "17619624           142           042                     1\n",
      "17619637           142           192                     1\n",
      "12408027          2035          2075                     1\n",
      "12408015          2035          2535                     1\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "def levenshtein_distance(seq1, seq2):\n",
    "    return Levenshtein.distance(seq1, seq2)\n",
    "\n",
    "# List to store the results\n",
    "distances = []\n",
    "def extract_subsequences(sequence, min_length=3, max_length=4):\n",
    "    subsequences = set()  # Using a set to store only unique subsequences\n",
    "    length = len(sequence)\n",
    "    \n",
    "    # Generate subsequences only within the length range (min_length to max_length)\n",
    "    for start in range(length):\n",
    "        for end in range(start + min_length, min(start + max_length + 1, length + 1)):\n",
    "            subsequences.add(sequence[start:end])\n",
    "    \n",
    "    return list(subsequences)\n",
    "\n",
    "all_subsequences = set()  # To store unique subsequences across all entries\n",
    "\n",
    "for sequence in train_seq_df['processed_str']:\n",
    "    subsequences = extract_subsequences(sequence)\n",
    "    all_subsequences.update(subsequences)\n",
    "all_subsequences = list(all_subsequences)\n",
    "\n",
    "print(f\"Total unique subsequences: {len(all_subsequences)}\")\n",
    "\n",
    "# # Step 2: Calculate Levenshtein distance between subsequences\n",
    "for i in range(len(all_subsequences)):\n",
    "    for j in range(i + 1, len(all_subsequences)):  # Only unique pairs\n",
    "        seq1 = all_subsequences[i]\n",
    "        seq2 = all_subsequences[j]\n",
    "        distance = Levenshtein.distance(seq1, seq2)\n",
    "        distances.append((seq1, seq2, distance))\n",
    "\n",
    "# Convert distances to DataFrame\n",
    "distance_df = pd.DataFrame(distances, columns=['Subsequence 1', 'Subsequence 2', 'Levenshtein Distance'])\n",
    "\n",
    "# Sort by Levenshtein distance in ascending order\n",
    "sorted_distance_df = distance_df.sort_values(by='Levenshtein Distance', ascending=True)\n",
    "\n",
    "# Step 3: Display the top 50 most similar subsequences\n",
    "top_50_similar = sorted_distance_df.head(50)\n",
    "\n",
    "# Print top 50 most similar subsequences\n",
    "print(top_50_similar)\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "903054e0-0d16-45e2-ba32-0356578f84c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Motif  Count\n",
      "1786   312996      3\n",
      "857    031322      3\n",
      "3638   786659      3\n",
      "41     022075      3\n",
      "1834   018990      3\n",
      "...       ...    ...\n",
      "3888   821919      1\n",
      "3889   131821      1\n",
      "3890   880555      1\n",
      "3891   805552      1\n",
      "10629  231899      1\n",
      "\n",
      "[10630 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_motifs(sequence, motif_length=6):\n",
    "    return [sequence[i:i + motif_length] for i in range(len(sequence) - motif_length + 1)]\n",
    "\n",
    "# Step 1: Extract all motifs from the dataset\n",
    "motif_length = 6  # Define the length of motifs to extract\n",
    "all_motifs = []\n",
    "\n",
    "for sequence in train_seq_df['processed_str']:\n",
    "    motifs = extract_motifs(sequence, motif_length)\n",
    "    all_motifs.extend(motifs)  # Collect all motifs\n",
    "\n",
    "# Step 2: Count the frequency of each motif\n",
    "motif_counts = Counter(all_motifs)\n",
    "\n",
    "# Step 3: Convert the counts to a DataFrame for better readability\n",
    "motif_counts_df = pd.DataFrame(motif_counts.items(), columns=['Motif', 'Count'])\n",
    "\n",
    "# Step 4: Sort motifs by count in descending order\n",
    "sorted_motifs_df = motif_counts_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Step 5: Display the top N motifs\n",
    "top_n = 20  # Specify how many top motifs to display\n",
    "print(sorted_motifs_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf78c8f-a2ad-439e-8947-4ad2194f9fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Occurring Patterns:\n",
      "Pattern: 1596, Count: 14160\n",
      "Pattern: 5436, Count: 7134\n",
      "Pattern: 1543, Count: 7082\n",
      "Pattern: 4262, Count: 5580\n",
      "Pattern: 4159, Count: 5388\n",
      "Pattern: 6142, Count: 5113\n",
      "Pattern: 5962, Count: 4942\n",
      "Pattern: 6141, Count: 4276\n",
      "Pattern: 2621, Count: 4155\n",
      "Pattern: 0000, Count: 3878\n",
      "Pattern: 6262, Count: 3875\n",
      "Pattern: 2614, Count: 3834\n",
      "Pattern: 6614, Count: 3812\n",
      "Pattern: 2159, Count: 3707\n",
      "Pattern: 1415, Count: 3621\n",
      "Pattern: 6215, Count: 3370\n",
      "Pattern: 4614, Count: 2932\n",
      "Pattern: 2622, Count: 2811\n",
      "Pattern: 1426, Count: 2738\n",
      "Pattern: 9626, Count: 2676\n",
      "Pattern: 2626, Count: 2645\n",
      "Pattern: 4221, Count: 2610\n",
      "Pattern: 9661, Count: 2589\n",
      "Pattern: 5966, Count: 2556\n",
      "Pattern: 6261, Count: 2542\n",
      "Pattern: 4641, Count: 2527\n",
      "Pattern: 0001, Count: 2400\n",
      "Pattern: 2624, Count: 2335\n",
      "Pattern: 5964, Count: 2201\n",
      "Pattern: 6144, Count: 2183\n",
      "Pattern: 2215, Count: 2145\n",
      "Pattern: 5961, Count: 2136\n",
      "Pattern: 2154, Count: 2069\n",
      "Pattern: 4364, Count: 2066\n",
      "Pattern: 4284, Count: 1999\n",
      "Pattern: 6415, Count: 1994\n",
      "Pattern: 6464, Count: 1990\n",
      "Pattern: 0015, Count: 1984\n",
      "Pattern: 4422, Count: 1983\n",
      "Pattern: 6422, Count: 1941\n",
      "Pattern: 2284, Count: 1938\n",
      "Pattern: 0004, Count: 1924\n",
      "Pattern: 2464, Count: 1908\n",
      "Pattern: 2842, Count: 1894\n",
      "Pattern: 4154, Count: 1884\n",
      "Pattern: 2841, Count: 1801\n",
      "Pattern: 6284, Count: 1797\n",
      "Pattern: 1428, Count: 1746\n",
      "Pattern: 6228, Count: 1741\n",
      "Pattern: 4642, Count: 1734\n",
      "Pattern: 4361, Count: 1694\n",
      "Pattern: 4362, Count: 1681\n",
      "Pattern: 4222, Count: 1677\n",
      "Pattern: 9628, Count: 1628\n",
      "Pattern: 2262, Count: 1532\n",
      "Pattern: 8415, Count: 1510\n",
      "Pattern: 0159, Count: 1493\n",
      "Pattern: 8426, Count: 1492\n",
      "Pattern: 0262, Count: 1462\n",
      "Pattern: 6159, Count: 1459\n",
      "Pattern: 0614, Count: 1413\n",
      "Pattern: 2846, Count: 1409\n",
      "Pattern: 8461, Count: 1359\n",
      "Pattern: 0002, Count: 1317\n",
      "Pattern: 9615, Count: 1263\n",
      "Pattern: 0154, Count: 1179\n",
      "Pattern: 4644, Count: 1153\n",
      "Pattern: 4366, Count: 1150\n",
      "Pattern: 4646, Count: 1138\n",
      "Pattern: 3626, Count: 1135\n",
      "Pattern: 6426, Count: 1134\n",
      "Pattern: 3615, Count: 1132\n",
      "Pattern: 4226, Count: 1125\n",
      "Pattern: 4224, Count: 1116\n",
      "Pattern: 2226, Count: 1108\n",
      "Pattern: 0422, Count: 1107\n",
      "Pattern: 0464, Count: 1105\n",
      "Pattern: 2261, Count: 1087\n",
      "Pattern: 3661, Count: 1080\n",
      "Pattern: 6154, Count: 1059\n",
      "Pattern: 4464, Count: 1045\n",
      "Pattern: 2422, Count: 1027\n",
      "Pattern: 6461, Count: 1019\n",
      "Pattern: 6242, Count: 1010\n",
      "Pattern: 0026, Count: 966\n",
      "Pattern: 3646, Count: 954\n",
      "Pattern: 2246, Count: 953\n",
      "Pattern: 9646, Count: 946\n",
      "Pattern: 0006, Count: 945\n",
      "Pattern: 6442, Count: 944\n",
      "Pattern: 0061, Count: 928\n",
      "Pattern: 6246, Count: 925\n",
      "Pattern: 1442, Count: 913\n",
      "Pattern: 3642, Count: 912\n",
      "Pattern: 0046, Count: 908\n",
      "Pattern: 9642, Count: 905\n",
      "Pattern: 1446, Count: 904\n",
      "Pattern: 0042, Count: 874\n",
      "Pattern: 2623, Count: 842\n",
      "Pattern: 6143, Count: 658\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "def extract_subsequences(string, length):\n",
    "    return [string[i:i + length] for i in range(len(string) - length + 1)]\n",
    "\n",
    "# Specify the length of th subsequences you want to extract\n",
    "subsequence_length = 4\n",
    "\n",
    "# Step 2: Count occurrences of subsequences\n",
    "subsequence_counter = Counter()\n",
    "\n",
    "for string in train_seq_df['input_str']:\n",
    "    subsequences = extract_subsequences(string, subsequence_length)\n",
    "    subsequence_counter.update(subsequences)\n",
    "\n",
    "# Step 3: Get the top 20 mo6142st common subsequences\n",
    "top_20_patterns = subsequence_counter.most_common(100)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 20 Most Occurring Patterns:\")\n",
    "for pattern, count in top_20_patterns:\n",
    "    print(f\"Pattern: {pattern}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efa12de-b64d-4ec7-b08e-47ce8eeaa706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.508475\n",
      "1    49.491525\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Plot label distribution\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x=train_seq_df['label'])\n",
    "plt.title('Label Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Print the distribution of labels in percentages\n",
    "label_counts = train_seq_df['label'].value_counts(normalize=True) * 100\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1b67f2f7-78b1-48c4-87ce-779ad7eabb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 9, 5, 1, 1, 0, 4, 7, 4, 7, 6, 1]\n",
      "Padded Sequences:\n",
      "[3 6 9 5 1 1 0 4 7 4 7 6 1]\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baftol/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.6741\n",
      "Epoch 2/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7072 - loss: 0.5644\n",
      "Epoch 3/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7723 - loss: 0.4834\n",
      "Epoch 4/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4291\n",
      "Epoch 5/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3733\n",
      "Epoch 6/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8577 - loss: 0.3318\n",
      "Epoch 7/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3085\n",
      "Epoch 8/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2862\n",
      "Epoch 9/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2655\n",
      "Epoch 10/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2529\n",
      "Epoch 11/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2415\n",
      "Epoch 12/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2149\n",
      "Epoch 13/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2169\n",
      "Epoch 14/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1941\n",
      "Epoch 15/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.1846\n",
      "Epoch 16/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.1805\n",
      "Epoch 17/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.1677\n",
      "Epoch 18/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.1604\n",
      "Epoch 19/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1563\n",
      "Epoch 20/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.1547\n",
      "Epoch 21/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1522\n",
      "Epoch 22/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.1406\n",
      "Epoch 23/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.1397\n",
      "Epoch 24/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1441\n",
      "Epoch 25/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1319\n",
      "Epoch 26/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.1353\n",
      "Epoch 27/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1243\n",
      "Epoch 28/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1217\n",
      "Epoch 29/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1234\n",
      "Epoch 30/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1114\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Neural Network Test Accuracy: 92.02%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_83\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_83\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_82 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │           \u001b[38;5;34m700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_82 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │         \u001b[38;5;34m7,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_80 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_165 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,025</span> (113.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,025\u001b[0m (113.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,441</span> (36.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,441\u001b[0m (36.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">700</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m700\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,884</span> (73.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,884\u001b[0m (73.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense,Conv2D, Dropout,SimpleRNN,GRU,Bidirectional\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "text_df = pd.read_csv('datasets/train/train_text_seq.csv')\n",
    "\n",
    "digit_to_int = {str(i): i for i in range(10)}\n",
    "\n",
    "# Convert each string to a list of integers\n",
    "train_seq_df['integer_list'] = train_seq_df['processed_str'].apply(lambda x: [digit_to_int[char] for char in x])\n",
    "valid_seq_df['integer_list'] = valid_seq_df['processed_str'].apply(lambda x: [digit_to_int[char] for char in x])\n",
    "\n",
    "print(train_seq_df['integer_list'].values[1])\n",
    "max_len = max(len(seq) for seq in train_seq_df['integer_list'])  # Find the maximum length of sequences\n",
    "max_len2 = max(len(seq) for seq in valid_seq_df['integer_list'])  # Find the maximum length of sequences\n",
    "\n",
    "# Step 4: Pad sequences to ensure uniform input lengths\n",
    "X_padded = pad_sequences(train_seq_df['integer_list'].tolist(), maxlen=max_len, padding='post')\n",
    "X_val_padded = pad_sequences(valid_seq_df['integer_list'].tolist(), maxlen=max_len, padding='post')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#rizer.fit_transform(X_padded)\n",
    "# y_encoded = train_seq_df['label'].values  # assuming labels are already integers or can be converted\n",
    "# X_val_padded = pad_sequences(modified_val_sequences, maxlen=max_len, padding='post')\n",
    "# X_padded = integer_sequences\n",
    "print(\"Padded Sequences:\")\n",
    "# print(X_padded)\n",
    "# print(X_val_padded[0])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(train_seq_df['label'])\n",
    "y_val_encoded = label_encoder.fit_transform(valid_seq_df['label'])\n",
    "# X_padded = np.array([np.sort(seq) for seq in X_padded])\n",
    "print(X_padded[1])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)\n",
    "# print(X_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer with pre-trained embeddings (trainable=False)\n",
    "model.add(Embedding(input_dim=len(X_train[0]) + 1, output_dim=50, input_length=max_len, trainable=False))\n",
    "\n",
    "# Convolutional layer with fewer filters\n",
    "# model.add(Conv2D(filters=64,kernel_size = (3,3),activation='relu'))\n",
    "model.add(Conv1D(filters=48, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# LSTM layer with fewer units\n",
    "model.add((SimpleRNN(16, return_sequences=False)))\n",
    "\n",
    "# Dense layers with Dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, verbose=1)\n",
    "y_pred = (model.predict(X_val_padded) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val_encoded, y_pred)\n",
    "print(f\"Neural Network Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "123c790e-3902-43f1-a844-c78ea186b155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 4 ... 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit KMeans on padded sequences to find clusters\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X_padded)\n",
    "labels = kmeans.labels_\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bde880ae-d997-40b7-8e5f-73c215360ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('299', 487), ('332', 436), ('452', 417), ('112', 417), ('430', 411), ('313', 403), ('207', 392), ('533', 391), ('195', 385), ('682', 380), ('182', 370), ('271', 368), ('327', 368), ('310', 348), ('999', 337), ('510', 335), ('486', 332), ('143', 319), ('355', 319), ('141', 317)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert sequences to string for n-gram analysis\n",
    "X_padded_str = [''.join(map(str, seq)) for seq in X_padded]\n",
    "\n",
    "# Extract bigrams and trigrams\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3,3)) \n",
    "ngram_counts = vectorizer.fit_transform(train_seq_df['processed_str'])\n",
    "\n",
    "# Get the top 20 most frequent n-grams\n",
    "sum_ngram_counts = ngram_counts.sum(axis=0) \n",
    "ngrams_freq = [(ngram, sum_ngram_counts[0, idx]) for ngram, idx in vectorizer.vocabulary_.items()]\n",
    "top_20_ngrams = sorted(ngrams_freq, key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "print(top_20_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c7edeed0-cba4-4639-bdba-45d6327dcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6905014\ttest: 0.6935028\tbest: 0.6935028 (0)\ttotal: 1.88ms\tremaining: 9.39s\n",
      "100:\tlearn: 0.9159605\ttest: 0.8637006\tbest: 0.8637006 (99)\ttotal: 144ms\tremaining: 6.97s\n",
      "200:\tlearn: 0.9682203\ttest: 0.8700565\tbest: 0.8700565 (170)\ttotal: 283ms\tremaining: 6.75s\n",
      "300:\tlearn: 0.9901130\ttest: 0.8764124\tbest: 0.8799435 (290)\ttotal: 421ms\tremaining: 6.58s\n",
      "400:\tlearn: 0.9962924\ttest: 0.8750000\tbest: 0.8799435 (290)\ttotal: 562ms\tremaining: 6.44s\n",
      "500:\tlearn: 0.9991172\ttest: 0.8764124\tbest: 0.8820621 (424)\ttotal: 702ms\tremaining: 6.3s\n",
      "600:\tlearn: 0.9998234\ttest: 0.8799435\tbest: 0.8820621 (424)\ttotal: 843ms\tremaining: 6.17s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8820621469\n",
      "bestIteration = 424\n",
      "\n",
      "Shrink model to first 425 iterations.\n",
      "CatBoost Test Accuracy: 86.09%\n",
      "{'nan_mode': 'Min', 'eval_metric': 'Accuracy', 'iterations': 5000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'od_pval': 0, 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'Lossguide', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 5, 'random_strength': 1, 'od_type': 'Iter', 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 1, 'use_best_model': True, 'od_wait': 200, 'class_names': [0, 1], 'random_seed': 42, 'depth': 4, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.25, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 31}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       252\n",
      "           1       0.85      0.86      0.86       237\n",
      "\n",
      "    accuracy                           0.86       489\n",
      "   macro avg       0.86      0.86      0.86       489\n",
      "weighted avg       0.86      0.86      0.86       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# X = emoji_features_numeric\n",
    "# y = train_emoticon_df['label']\n",
    "# Assuming X and y are your feature matrix and labels respectively\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize CatBoostClassifier\n",
    "catboost_clf = CatBoostClassifier(\n",
    "    iterations=5000,           # Number of boosting iterations\n",
    "    learning_rate=0.25,        # Learning rate\n",
    "    depth=4,                  # Depth of the trees\n",
    "    eval_metric='Accuracy',   # Use accuracy as evaluation metric\n",
    "    random_seed=42,           # For reproducibility\n",
    "    verbose=100,\n",
    "    # sampling_frequency='PerTreeLevel',\n",
    "    l2_leaf_reg = 5,\n",
    "    subsample = 1.0,\n",
    "    loss_function = 'Logloss',\n",
    "    grow_policy='Lossguide',\n",
    "    leaf_estimation_method='Newton',\n",
    "    leaf_estimation_backtracking='AnyImprovement',\n",
    "    boost_from_average=False,\n",
    "    allow_const_label=True,\n",
    "    model_shrink_mode='Constant',\n",
    "    # score_function='NewtonL2',\n",
    "    # task_type='GPU',\n",
    "    # boosting_type='Ordered',\n",
    "    # auto_class_weights=None,\n",
    "    # sampling_unit = 'Group'\n",
    "    # max_leaves = 10,\n",
    "     # Prints training process every 100 iterations\n",
    ")\n",
    "# Fit the model to the training data\n",
    "catboost_clf.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=200)\n",
    "# Make predictions on the test set\n",
    "y_pred = catboost_clf.predict(X_val_padded)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_encoded, y_pred)\n",
    "print(f\"CatBoost Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "params = catboost_clf.get_all_params()\n",
    "print(params)\n",
    "# Print detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_encoded, y_pred))\n",
    "# Get feature importance\n",
    "# feature_importances = catboost_clf.get_feature_importance()\n",
    "\n",
    "# # Print or plot feature importance\n",
    "# # for i, importance in enumerate(feature_importances):\n",
    "# #     print(f\"Feature {i}: Importance = {importance}\")\n",
    "\n",
    "# # Create a DataFrame to analyze misclassifications\n",
    "# results_df = pd.DataFrame({'True Label': y_test, 'Predicted Label': y_pred})\n",
    "\n",
    "# # Identify misclassified samples\n",
    "# misclassified = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "# print(f\"Number of misclassified samples: {len(misclassified)}\")\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "#             xticklabels=['Class 0', 'Class 1'], \n",
    "#             yticklabels=['Class 0', 'Class 1'])\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "# Optionally visualize misclassified instances\n",
    "# For example, if your data is textual, you might want to display some examples:\n",
    "\n",
    "# Example of analyzing features of misclassified samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160b401-efbc-4132-a9f1-64da18da80cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb82e9-2e3b-4a75-952c-e5876d8e64c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
